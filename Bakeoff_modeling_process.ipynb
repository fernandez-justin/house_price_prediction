{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kings County Housing Prices Bakeoff\n",
    "\n",
    "Below are a list of steps that you should take while trying to complete your bake-off entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# for looking at models r-squared, coefficients, and p-values\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# used to change date feature\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "# for stats tests\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "# used to get subset of overall dataset\n",
    "from scipy.stats.mstats import winsorize\n",
    "# used to get train test split for model testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "# for feature selection\n",
    "from sklearn.feature_selection import RFECV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kc_house_data_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary column, provides no info\n",
    "df = df.drop(['Unnamed: 0','id'], axis=1)\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking at the data itself\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if any major outliers\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking to see if any features correlate with price\n",
    "df.corr()['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at regression plots to see if any trends are immediatly present\n",
    "x_sqft = df.sqft_living\n",
    "x_grade = df.grade\n",
    "x_sqft15 = df.sqft_living15\n",
    "x_view = df.view\n",
    "y_price_test = df.price\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(10,10))\n",
    "ax[0,0].scatter(x_sqft,y_price_test,color='red')\n",
    "ax[0,0].set_xlabel('sqft_living')\n",
    "ax[0,0].set_ylabel('price')\n",
    "ax[0,1].scatter(x_grade,y_price_test,color='pink')\n",
    "ax[0,1].set_xlabel('grade')\n",
    "ax[0,1].set_ylabel('price')\n",
    "ax[1,0].scatter(x_sqft15,y_price_test,color='tomato')\n",
    "ax[1,0].set_xlabel('sqft_living15')\n",
    "ax[1,0].set_ylabel('price')\n",
    "ax[1,1].scatter(x_view,y_price_test,color='firebrick')\n",
    "ax[1,1].set_xlabel('view')\n",
    "ax[1,1].set_ylabel('price')\n",
    "\n",
    "fig.savefig('scatter_for_git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Left commented due to the time it takes to run this pairplot\n",
    "# was very helpful to identify categorical variables\n",
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# regression plot to see the correlation\n",
    "sns.regplot('sqft_living','price',data=df,color='green',line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression plot to see the correlation\n",
    "sns.regplot('grade','price',data=df,color='darkorange',line_kws={\"color\": \"navy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up any issues (extreme values, etc.) with the data.  \n",
    "\n",
    "Remember that you can't just delete rows with extreme values. Similar observations might be present in the holdout data set, and you can't just delete those rows and not have a prediction for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OUTLIERS\n",
    "- bed and bath seem to have some extreme values\n",
    "- sqft has a large outlier\n",
    "- sqft 15 has outlier but assuming fancy neighbor hood\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([10, 4, 9, 8, 5, 3, 7, 2, 1, 6])\n",
    "winsorize(a, limits=[0.1, 0.1],inclusive=(False,True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I am going to change the date column to a more usable datetime object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feature: Month Sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to look to see if the month the house was sold has any affect on the price it was sold for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting date to a real datetime\n",
    "df.date = pd.to_datetime(df['date'])\n",
    "# extracting just the month\n",
    "df['month_sold'] = df.date.dt.month\n",
    "# grouping to see price per month\n",
    "selling_month = df.groupby(['month_sold']).mean()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick visualization to see if anything sticks out\n",
    "x = selling_month.index\n",
    "y = selling_month.values\n",
    "fig = plt.figure(figsize = (6,4))\n",
    "ax = fig.add_subplot()\n",
    "ax.bar(x,y,color='salmon')\n",
    "ax.set_title('Month Sold vs Price')\n",
    "ax.set_xlabel('Month Sold')\n",
    "ax.set_ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can see that there is a variation in price based on the month it was sold. The difference between the lowest and the highest is only about $6,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feature: Year Since Renovation/Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to look to see if the time since the house was last imporoved or built has any affect on the price of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using np.select to find the years since it was built or renovated\n",
    "# if it was renovated\n",
    "conditions = [\n",
    "    df['yr_renovated'] != 0,\n",
    "]\n",
    "# set the years since build to 2020 - that year to get the # of years\n",
    "# the data stops at 2015 but all of these will be changed so the time since does not matter\n",
    "choices = [\n",
    "    2020-df['yr_renovated']\n",
    "]\n",
    "# if not renovated defaults to the year it was built\n",
    "df['yr_since_build'] = np.select(conditions,choices,default=(2020-df['yr_built']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using scatter to see if any trends stick out\n",
    "x = df['yr_since_build']\n",
    "y = df['price']\n",
    "fig = plt.figure(figsize = (6,4))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(x,y,color='purple')\n",
    "ax.set_title('Year Since Built vs Price ')\n",
    "ax.set_xlabel('Year Since Build')\n",
    "ax.set_ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feature: Is Multi Floor Home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is going to be created because I want to see if there is any major price increase for houses that have multiple floors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking at the counts of floors per home\n",
    "df.floors.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lambda to see if floors is greater than 1\n",
    "df['is_multi_floor'] = df['floors'].apply(lambda x: 1 if x > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# totally even split of \n",
    "df.is_multi_floor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking at differences in prices\n",
    "df.groupby('is_multi_floor').mean()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10))\n",
    "sns.scatterplot(df.grade,df.price,hue=df.is_multi_floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feature: If House has new basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lambda to see if there is a square footage for the beasement\n",
    "df['has_basement'] = df['sqft_basement'].apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# looking at counts to see the spread\n",
    "df['has_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# see if the prices differ\n",
    "df.groupby('has_basement').mean()['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalizing feature dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'bedrooms',\n",
    "    'bathrooms',\n",
    "    'sqft_living',\n",
    "    'sqft_lot',\n",
    "    'floors',\n",
    "    'waterfront',\n",
    "    'view',\n",
    "    'condition',\n",
    "    'grade',\n",
    "    'sqft_above',\n",
    "    'sqft_basement',\n",
    "    'yr_built',\n",
    "    'yr_renovated',\n",
    "    'sqft_living15',\n",
    "    'sqft_lot15',\n",
    "    'month_sold',\n",
    "    'yr_since_build',\n",
    "    'is_multi_floor',\n",
    "    'has_basement'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df[features]\n",
    "target = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating polynomial feature from the grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the look of the graph that we saw for grade, I thought that a polynomial feature could better describe that output. I was doing this manually but this will be encorporated in the larger polynomial combinations we make after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data I need out\n",
    "tdf = df[['price','grade']]\n",
    "x = tdf.drop(columns='price',axis=1)\n",
    "y = tdf['price']\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color='green')\n",
    "plt.xlabel('grade')\n",
    "plt.ylabel('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#x.reshape(-1,1)\n",
    "reg = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, color='green')\n",
    "plt.plot(x, reg.predict(x))\n",
    "plt.xlabel('view')\n",
    "plt.ylabel('price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['grade_square'] = x.grade**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x.grade, y, color='green')\n",
    "plt.plot(x['grade'], reg.predict(x))\n",
    "plt.xlabel('grade')\n",
    "plt.ylabel('price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow us to make combinations of all features up to a certain degree. I am going to make these now and test later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of new dataframe for polynomials of degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiating the object\n",
    "poly2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "# transforming my features\n",
    "poly2_data = poly2.fit_transform(df_features)\n",
    "# creating the new data frame\n",
    "poly2_cols = poly2.get_feature_names(df_features.columns)\n",
    "df_poly2 = pd.DataFrame(poly2_data,columns = poly2_cols)\n",
    "df_poly2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of new dataframe for polynomials of degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiating the object\n",
    "poly3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "# transforming my features\n",
    "poly3_data = poly3.fit_transform(df_features)\n",
    "# creating the new data frame\n",
    "poly3_cols = poly3.get_feature_names(df_features.columns)\n",
    "df_poly3 = pd.DataFrame(poly3_data,columns = poly3_cols)\n",
    "df_poly3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests\n",
    "\n",
    "#### Number 1\n",
    "* Ho - There is no difference in price between waterfront and not\n",
    "* Ha - There is a difference in price\n",
    "\n",
    "#### Number 2\n",
    "* Ho - A basement will not increase the price of a home\n",
    "* Ha - A basement will increase a price of a home\n",
    "\n",
    "#### Number 3\n",
    "* Ho - a house is the same sqft as its 15 neighbors\n",
    "* Ha - a house is not the same as the 15 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# going to use a two sample t-test\n",
    "# getting the two samples\n",
    "water = df[df['waterfront'] > 0.5]\n",
    "land = df[(df.waterfront < 0.5)]\n",
    "# degrees of freedom with this case\n",
    "dfree = len(water) + len(land) - 1\n",
    "# going for a 5% alpha with 2.5% on each side\n",
    "a = 0.025\n",
    "value= t.ppf(a, dfree)\n",
    "print('the critical value is '+str(value))\n",
    "p = t.cdf(value,dfree)\n",
    "print('the p value is '+str(p))\n",
    "stats.ttest_ind(water['price'], land['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can reject the null hypothesis so we can see that waterfront definitly does change the price**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basement = df[df['has_basement'] == 1]\n",
    "nobase = df[df['has_basement'] == 0]\n",
    "dfree = len(basement) + len(nobase) - 2\n",
    "a = 0.05\n",
    "value= t.ppf(a, dfree)\n",
    "print('the critical value is '+str(value))\n",
    "p = t.cdf(value,dfree)\n",
    "print('the p value is '+str(p))\n",
    "stats.ttest_ind(basement['price'], nobase['price'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can reject the null hypothesis so we can see that a basement does increase the price**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# going to use a two-tailed t-test to tell if these two groups are the same or different\n",
    "my_house = df.sqft_living\n",
    "neighbors = df.sqft_living15\n",
    "\n",
    "a = 0.025\n",
    "dfree = len(my_house) + len(neighbors) - 2\n",
    "\n",
    "value= t.ppf(a, dfree)\n",
    "print('the critical value is '+str(value))\n",
    "p = t.cdf(value,dfree)\n",
    "print('the p value is '+str(p))\n",
    "stats.ttest_ind(my_house, neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can reject the null hypothesis so we can say that with 95% confidence our house is likely to be different in square footage than our neighbors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Train-Test Split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a train-test split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, target, random_state=9,test_size=0.2)\n",
    "print(len(X_train), \"train +\", len(X_test), \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# fit the scaler to the training data\n",
    "scaler.fit(X_train)\n",
    "# transforming the training data\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train), columns = df_features.columns)\n",
    "# transforming the test data seperatley\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns = df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing this data on a linear regression\n",
    "LinReg = LinearRegression()\n",
    "# fitting our object to the data\n",
    "LinReg = LinReg.fit(X_train,y_train)\n",
    "# making predictions on our y_train\n",
    "y_train_pred = LinReg.predict(X_train)\n",
    "# getting the RSME\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating what we have done on the test set\n",
    "# using the fitted model to predict on our test (holdout)\n",
    "y_test_pred = LinReg.predict(X_test)\n",
    "# getting rsme\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test,y_test_pred))\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing polynomials of degree 2 for RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new test train split for polynomials\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_poly2, target, random_state=9,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a scaler\n",
    "scaler_p2 = StandardScaler()\n",
    "# fit the scaler to the training data\n",
    "scaler_p2.fit(X_train)\n",
    "# transforming the training data\n",
    "X_train = pd.DataFrame(data=scaler_p2.transform(X_train), columns = df_poly2.columns)\n",
    "# transforming the test data seperatley\n",
    "X_test = pd.DataFrame(data=scaler_p2.transform(X_test), columns = df_poly2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing this data on a linear regression\n",
    "LinReg_p2 = LinearRegression()\n",
    "# fitting our object to the data\n",
    "LinReg_p2 = LinReg.fit(X_train,y_train)\n",
    "# making predictions on our y_train\n",
    "y_train_pred = LinReg_p2.predict(X_train)\n",
    "# getting the RSME\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluating what we have done on the test set\n",
    "# using the fitted model to predict on our test (holdout)\n",
    "y_test_pred = LinReg_p2.predict(X_test)\n",
    "# getting rsme\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test,y_test_pred))\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing polynomials of degree 3 for RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new test train split for polynomials\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_poly3, target, random_state=4,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a scaler\n",
    "scaler_p3 = StandardScaler()\n",
    "# fit the scaler to the training data\n",
    "scaler_p3.fit(X_train)\n",
    "# transforming the training data\n",
    "X_train = pd.DataFrame(data=scaler_p3.transform(X_train), columns = df_poly3.columns)\n",
    "# transforming the test data seperatley\n",
    "X_test = pd.DataFrame(data=scaler_p3.transform(X_test), columns = df_poly3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing this data on a linear regression\n",
    "LinReg_p3 = LinearRegression()\n",
    "# fitting our object to the data\n",
    "LinReg_p3 = LinReg.fit(X_train,y_train)\n",
    "# making predictions on our y_train\n",
    "y_train_pred = LinReg_p3.predict(X_train)\n",
    "# getting the RSME\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating what we have done on the test set\n",
    "# using the fitted model to predict on our test (holdout)\n",
    "y_test_pred = LinReg_p3.predict(X_test)\n",
    "# getting rsme\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test,y_test_pred))\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is VERY overfit and needs to be run through a feature selection process in order to determine its usefullness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Method Using Select K-Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using poly_2 as it was the best performing and not overfit\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_poly2, target, random_state=9,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* I am using poly_2 as it performed the best after doing feature seleciton and with so many features the wrapper method took too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of features I want to end with\n",
    "k = round(np.sqrt(len(df_poly2)))\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f_regression as ranking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a feature selector object\n",
    "feature_selector = SelectKBest(f_regression,131)\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# features that we kepy\n",
    "selected_features = X_train.columns[feature_selector.get_support()]\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test that for the regression\n",
    "# instantiate a linear regression object\n",
    "LR_kbest_F = LinearRegression()\n",
    "# fit the linear regression to the data\n",
    "LR_kbest_F = LR_kbest_F.fit(X_train[selected_features], y_train)\n",
    "# predicting on the data\n",
    "y_train_kbest_F = LR_kbest_F.predict(X_train[selected_features])\n",
    "# getting the rsme\n",
    "train_kbest_F_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_kbest_F))\n",
    "print('Training Root Mean Squared Error:' , train_kbest_F_rmse)\n",
    "# predicting on test set\n",
    "y_kbest_F = LR_kbest_F.predict(X_test[selected_features])\n",
    "# getting RSME\n",
    "test_kbest_F_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_kbest_F))\n",
    "print('Testing Root Mean Squared Error:' , test_kbest_F_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this performed much worse than having all features did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information as ranking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiating a feature selector object\n",
    "feature_selector = SelectKBest(mutual_info_regression, k)\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# features that we kepy\n",
    "selected_features_MI = X_train.columns[feature_selector.get_support()]\n",
    "len(selected_features_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test that for the regression\n",
    "# instantiate a linear regression object\n",
    "LinReg_kbestMI = LinearRegression()\n",
    "# fit the linear regression to the data\n",
    "LinReg_kbestMI = LinReg_kbestMI.fit(X_train[selected_features], y_train)\n",
    "# predicting on the data\n",
    "y_train_kbestMI = LinReg_kbestMI.predict(X_train[selected_features])\n",
    "# getting the rsme\n",
    "trainKMI_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_kbestMI))\n",
    "print('Training Root Mean Squared Error:' , trainKMI_rmse)\n",
    "# predicting on test set\n",
    "y_kbestMI = LinReg_kbestMI.predict(X_test[selected_features])\n",
    "# getting RSME\n",
    "testKMI_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_kbestMI))\n",
    "print('Testing Root Mean Squared Error:' , testKMI_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing ols model as our esimation of 'goodness'\n",
    "ols = LinearRegression()\n",
    "# creating a selector object\n",
    "feature_selector = RFECV(estimator=ols, step=1, cv=5, scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_wrapper = X_train.columns[feature_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test that for the regression\n",
    "# instantiate a linear regression object\n",
    "LR_wrapper = LinearRegression()\n",
    "# fit the linear regression to the data\n",
    "LR_wrapper = LR_wrapper.fit(X_train[selected_wrapper], y_train)\n",
    "# predicting on the data\n",
    "y_train_wrapper = LR_wrapper.predict(X_train[selected_wrapper])\n",
    "# getting the rsme\n",
    "train_w_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_wrapper))\n",
    "print('Training Root Mean Squared Error:' , trainW_rmse)\n",
    "# predicting on test set\n",
    "y_wrapper_pred = LR_wrapper.predict(X_test[selected_wrapper])\n",
    "# getting RSME\n",
    "test_W_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_wrapper_pred))\n",
    "print('Testing Root Mean Squared Error:' , test_W_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at which model performed the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('K-Best F-Regression RMSE:' , testKF_rmse)\n",
    "print('K-Best Mutual Info RMSE:' , testKMI_rmse)\n",
    "print('Wrapper RMSE:' , testW_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results our wrapper method performs the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refiting best model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df_poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator for the wrapper method\n",
    "ols = LinearRegression()\n",
    "# final feature selector\n",
    "feature_selector = RFECV(estimator=ols, step=1, cv=5, scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "# fitting to the final df\n",
    "feature_selector.fit(df_poly2,target)\n",
    "# getting the selected features\n",
    "selected_features_final = final_df.columns[feature_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(selected_features_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LinReg_final = LinearRegression()\n",
    "# fitting to the whole dataset\n",
    "LinReg_final = LinReg_final.fit(df_poly2[selected_features_final],target)\n",
    "# getting coeficients\n",
    "LinReg_final.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"R^2 Score:\", LinReg_final.score(final_df[selected_features_final], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The r-squared looks quite good accounting for 76% of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making our final predicitons\n",
    "y_pred_final = LinReg_final.predict(df_poly2[selected_features_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = metrics.mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', train_mae )\n",
    "print('Mean Squared Error:',  train_mse)\n",
    "print('Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (\"R^2 Score:\", LinReg_final.score(df_poly2[selected_features_final],target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared seems quite good accounting for almost 76% of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = LinReg_final.predict(df_poly2[selected_features_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import the metrics module from sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "train_mae = metrics.mean_absolute_error(target, y_pred_final)\n",
    "train_mse = metrics.mean_squared_error(target, y_pred_final)\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(target, y_pred_final))\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', train_mae )\n",
    "print('Mean Squared Error:',  train_mse)\n",
    "print('Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the model performed quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to look if our residuals are evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = (target - y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals,bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does look normally distributed but the density in the middle leeds me to believe it is leptokurtic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking to see if our errors are IID and homoscedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_pred_final, target, lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somewhat concerning becuase I do see a downward trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in enumerate(zip(selected_features_final,LinReg_final.coef_)):\n",
    "    print('{}. {}: {}'.format(item[0]+1,item[1][0],item[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our selected features above we can see that there are some key feautres that played a part in the model.\n",
    "\n",
    "`sqft_living` was part of most of the features that we ended up with and this makes a lot of sense. As a house gets bigger it is going to be more expensive. Not only does this mean that it was more expensive to build but that it most likely sits on a larger property or has multiple stories.\n",
    "\n",
    "`bedrooms` and `bathrooms` also were a part of many of the features selected. This makes sense because as a house gets bigger and is being built to fit more people you are going to need more bedrooms and bathrooms.\n",
    "\n",
    "`grade` was a part of many of the interactions made in the polynomial generation. This makes sense as the 'better' quality that the house is evaluated to be the more expensive it will be.\n",
    "\n",
    "As for the coeficients we can see that some are positive and some are negative. I take this as the fine tuning that the model did to interpret how much a houses value would go up and down based on the value of that feature. Due to the scaler that we used we are evalutating these features as their affect on a house price based on standard deviations changes in the feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling\n",
    "\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open('model.pickle','wb')\n",
    "pickle.dump(LinReg_final, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('scaler.pickle','wb')\n",
    "pickle.dump(scaler, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
